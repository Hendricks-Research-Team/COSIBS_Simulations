---
title: "PRS Residual Analysis - White REGARDS Subjects"
author: "Jack Pattee"
date: "10/26/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(cluster)
library(mclust)
library(car)
library(ggplot2)
library(pROC)
library(MASS)

set.seed(3308004)

###read in white subjects PRSs and baseline data
dat = read.csv("~/Documents/Hendricks PRS/regards_data/trait_grs_env.csv")

###some vectors for use later
covarVec = c("Gender_x", "poly(Age_x, degree = 2)", "Alc_Use", "Income", "Smoke", "ED_Cat", "Weight")
pgsVec = c("PGS000684", "PGS000302", "PGS000061", "PGS000301", "PGS000062", "PGS000066", "PGS000297", "PGS000011")
outcomeVec = c("Glucose", "DBP", "Ldl", "SBP", "Cholest", "Trigly", "Height", "CAD")
outcomeFormat = c("Glucose", "DBP","LDL", "SBP", "TC", "TG", "Height", "CAD")
covarFormat = c("Gender","Age","Alcohol","Income","Smoking","Ed","Weight")

###some formatting
dat$Smoke[dat$Smoke==""] = NA
dat$ED_Cat[dat$ED_Cat==""] = NA
dat$CAD_SR_ECG[dat$CAD_SR_ECG==""] = NA
dat$CAD = ifelse(dat$CAD_SR_ECG=="Y",1,0)
```

This document describes application of the PRS residualization approach to white subjects in the regards data. In particular, seven covariates are considered: alcohol use, gender, age, smoking, education (categorical), income, and weight. Age is modeled as a polynomial with a squared term. Eight outcomes (and their polygenic risk scores are considered): diastolic blood pressure (‘PGS000302’), glucose (‘PGS000684’), LDL (‘PGS000061’), systolic blood pressure (‘PGS000301’), total cholesterol (‘PGS000062’), triglycerides (‘PGS000066’), coronary artery disease (‘PGS000011’), and height (‘PGS000297’). All of these outcomes are continuous, with the exception of coronary artery disease. For CAD, Pearson residuals will be used.

First, models will be fit with all seven covariates, and the residuals will be analyzed for structure. Then, models will be fit holding out each of the covariates in turn. All sets of residuals from leave-one-out models will be assessed via PCA and k-means clustering. For dichotomous or trichotomous covariates (smoking, alcohol use, gender), particular attention will be paid to k-means clustering.

```{r, echo = FALSE}
nmDat = dat[complete.cases(dat[,which(colnames(dat)%in%c(covarVec,pgsVec,outcomeVec))]),]
```

Subjects with missing data for any of the covariates, PGSs, or outcomes will be dropped from the analysis. This leaves us with a sample size of `r nrow(nmDat)` for a complete-case analysis.

As a case study, we first estimate the glucose multiple regression using all seven covariates. Some diagnostic plots are below. The multiple regression for glucose using the PGS and all seven covariates appears to deviate moderately from the modeling assumptions of linear regression. Given that we do not want to perform inference on the regression coefficients, this does not seem like a major issue. In fact, given that we may hope the residuals to have some type of 'bimodal' structure in some cases, it may in fact be preferrable that the residuals are not perfectly normal.

```{r, echo = FALSE}
###fit models for all eight outcomes with all seven covariates and the PRS
for(i in 1:length(outcomeVec)){
  tempOutcome = outcomeVec[i]
  tempFormula = as.formula(paste0(tempOutcome,"~",paste0(c(pgsVec[i],covarVec), collapse = "+")))
  if(tempOutcome!="CAD"){
    assign(paste0(outcomeFormat[i],"Full"), lm(tempFormula,data = nmDat))
  }else{
    assign(paste0(outcomeFormat[i],"Full"), glm(tempFormula,data = nmDat, family = "binomial"))
  }
}

###fit models for all eight outcomes with all seven clinical covariates and no PRS
for(i in 1:length(outcomeVec)){
  tempOutcome = outcomeVec[i]
  tempFormula = as.formula(paste0(tempOutcome,"~",paste0(covarVec, collapse = "+")))
  if(tempOutcome!="CAD"){
    assign(paste0(outcomeFormat[i],"NoPgs"), lm(tempFormula,data = nmDat))
  }else{
    assign(paste0(outcomeFormat[i],"NoPgs"), glm(tempFormula,data = nmDat, family = "binomial"))
  }
}

###fit models for all eight outcomes holding exactly one covariate out each time
for(i in 1:length(outcomeVec)){
  for(j in 1:length(covarVec)){
    tempOutcome = outcomeVec[i]
    tempFormula = as.formula(paste0(tempOutcome,"~",paste0(c(pgsVec[i],covarVec[-j]), collapse = "+")))
    if(tempOutcome!="CAD"){
      assign(paste0(outcomeFormat[i],"No",covarFormat[j]), lm(tempFormula,data = nmDat))
    }else{
      assign(paste0(outcomeFormat[i],"No",covarFormat[j]), glm(tempFormula,data = nmDat, family = "binomial"))
    }
  }
}

###get residuals for the full model
fullResids = as.data.frame(matrix(NA, nrow = nrow(nmDat), ncol = length(outcomeVec)))
colnames(fullResids) = outcomeFormat
for(i in 1:length(outcomeVec)){
  tempOutcome = outcomeFormat[i]
  tempMod = get(paste0(tempOutcome,"Full"))
  if(tempOutcome!="CAD"){
    fullResids[,i] = studres(tempMod)
  }else{
    fullResids[,i] = residuals(tempMod, type = "pearson")
  }
}
fullResids = scale(fullResids)

###get residuals for the hold-one-out models
for(j in 1:length(covarVec)){
  tempCovar = covarFormat[j]
  tempResids = as.data.frame(matrix(NA, nrow = nrow(nmDat), ncol = length(outcomeVec)))
  for(i in 1:length(outcomeVec)){
    tempOutcome = outcomeFormat[i]
    tempMod = get(paste0(tempOutcome,"No",tempCovar))
    if(tempOutcome!="CAD"){
      tempResids[,i] = studres(tempMod)
    }else{
      tempResids[,i] = residuals(tempMod, type = "pearson")
    }
  }
  tempResids = scale(tempResids)
  assign(paste0("no",tempCovar,"Resids"),tempResids)
}

hist(dat$Glucose, main = "Distribution of Glucose", xlab = "Glucose")
plot(GlucoseFull)
```

Investigate the variance inflation factor for the seven covariates.

```{r, echo = FALSE}
print(vif(GlucoseNoPgs))
```

Calculate the coefficient of determination for each of the models to give a sense of how predictive each covariate is. For the logistic CAD models, use AUROC.

```{r, echo = FALSE, warning=FALSE}
iterVec = c("Full","Pgs",covarFormat)
for(j in 1:length(outcomeFormat)){
  tempOutcome = outcomeFormat[j]
  tempRsqs = rep(NA, length(iterVec))
  for(i in 1:length(iterVec)){
    tempCovar = iterVec[i]
    if(tempCovar=="Full"){
      tempMod = get(paste0(tempOutcome,"Full"))
    }else{
      tempMod = get(paste0(tempOutcome,"No",tempCovar))
    }
    if(tempOutcome!="CAD"){
      tempRsqs[i] = summary(tempMod)$r.squared
    }else{
      tempRsqs[i] = auc(nmDat$CAD,predict(tempMod))
    }
  }
  assign(paste0(tempOutcome,"R2"),tempRsqs)
}

###make CAD plot manually
ggDatCAD = cbind.data.frame(iterVec,CADR2, Index=1:length(iterVec))
ggCAD = ggplot(data = ggDatCAD, aes(y = CADR2, x = Index, label = iterVec)) + geom_line() + geom_point() + geom_text(hjust = 1, vjust = 0) + 
  xlab(NULL) + ylab("AUC") + theme(axis.text.x = element_blank()) + ggtitle("CAD Regression Performance")
print(ggCAD)

###plot the other seven outcomes
for(i in 1:length(outcomeFormat)){
  tempOutcome = outcomeFormat[i]
  if(tempOutcome!="CAD"){
    ggDatTemp = cbind.data.frame(iterVec, get(paste0(tempOutcome,"R2")), Index = 1:length(iterVec))
    colnames(ggDatTemp)[2] = paste0(tempOutcome,"R2")
    tempPlot = ggplot(data = ggDatTemp, aes(y = get(paste0(tempOutcome,"R2")), x = Index, label = iterVec)) +
      geom_line() + geom_point() + geom_text(hjust = 1, vjust = 0) +
      xlab(NULL) + ylab("R2") + theme(axis.text.x = element_blank()) + ggtitle(paste0(tempOutcome," Regression Performance"))
    print(tempPlot)
  }
}
```

Assess clustering of the residuals from the full model using the gap statistic to determine the preferred number of clusters. Plot the first two principal components and look for structure. Studentized residuals will be used; these residuals are also scaled to ensure unit variance.
```{r, echo = FALSE}
fullGap = clusGap(fullResids, FUN = kmeans, nstart = 10, K.max = 10, B = 10)
plot(fullGap, main = "K-Means Gap Stat - all covariates")

pcFull = prcomp(fullResids)
plot(pcFull$x[,1],pcFull$x[,2], xlab = "PC1", ylab = "PC2", main = "All Covariates")
```

Assess clustering of the residuals from the model without gender using the gap statistic to determine the preferred number of clusters. Plot the first two principal components and look for structure.

```{r, echo = FALSE}
###gap statistic: no normalization
noGenderGap = clusGap(noGenderResids, FUN = kmeans, nstart = 10, K.max = 10, B = 10)
plot(noGenderGap, main = "K-Means Gap Stat - no gender")

pcNg = prcomp(noGenderResids)
ggNg = as.data.frame(pcNg$x)
ggNg$Gender = nmDat$Gender_x
ggScatterNg = ggplot(ggNg, aes(x = PC1, y = PC2, color = Gender)) + geom_point() + ggtitle("No gender")
print(ggScatterNg)

boxplot(ggNg$PC1~ggNg$Gender, xlab = "Gender", ylab = "PC1", main = "No gender")
boxplot(ggNg$PC2~ggNg$Gender, xlab = "Gender", ylab = "PC2", main = "No gender")

twoCenterNg = kmeans(noGenderResids, centers = 2, nstart = 3)
print(paste0("Adjusted rand index, no gender: ", round(adjustedRandIndex(twoCenterNg$cluster, nmDat$Gender_x), 3)))
print("No gender table of clustering results")
print(table(twoCenterNg$cluster, nmDat$Gender_x))
```

Assess residuals from the model without smoking.

```{r, echo = FALSE}
noSmokingGap = clusGap(noSmokingResids, FUN = kmeans, nstart = 10, K.max = 10, B = 10)
plot(noSmokingGap, main = "K-Means Gap Stat - no smoking")

pcNs = prcomp(noSmokingResids)
ggNs = as.data.frame(pcNs$x)
ggNs$Smoking = nmDat$Smoke
ggScatterNs = ggplot(ggNs, aes(x = PC1, y = PC2, color = Smoking)) + geom_point() + ggtitle("No smoking")
print(ggScatterNs)

boxplot(ggNs$PC1~ggNs$Smoking, xlab = "Smoking", ylab = "PC1", main = "No smoking")
boxplot(ggNs$PC2~ggNs$Smoking, xlab = "Smoking", ylab = "PC2", main = "No smoking")

threeCenterNs = kmeans(noSmokingResids, centers = 3, nstart = 3)
print(paste0("Adjusted rand index, no smoking: ", round(adjustedRandIndex(threeCenterNs$cluster, nmDat$Smoke), 3)))
print("No smoking table of clustering results")
print(table(threeCenterNs$cluster, nmDat$Smoke))
```

Assess residuals from the model without alcohol.

```{r, echo = FALSE}
noAlcoholGap = clusGap(noAlcoholResids, FUN = kmeans, nstart = 10, K.max = 10, B = 10)
plot(noAlcoholGap, main = "K-Means Gap Stat - no alcohol")

pcNa = prcomp(noAlcoholResids)
ggNa = as.data.frame(pcNa$x)
ggNa$Alcohol = nmDat$Alc_Use
ggScatterNa = ggplot(ggNa, aes(x = PC1, y = PC2, color = Alcohol)) + geom_point() + ggtitle("No alcohol")
print(ggScatterNa)

boxplot(ggNa$PC1~ggNa$Alcohol, xlab = "Alcohol", ylab = "PC1", main = "No alcohol")
boxplot(ggNa$PC2~ggNa$Alcohol, xlab = "Alcohol", ylab = "PC2", main = "No alcohol")

threeCenterNa = kmeans(noAlcoholResids, centers = 3, nstart = 3)
print(paste0("Adjusted rand index, no alcohol: ", round(adjustedRandIndex(threeCenterNa$cluster, nmDat$Alc_Use), 3)))
print("No alcohol table of clustering results")
print(table(threeCenterNa$cluster, nmDat$Alc_Use))
```

Assess residuals from the model without weight. There appears to be an oddly large number of duplicate values for weight - this warrants further investigation.

```{r, echo = FALSE}
noWeightGap = clusGap(noWeightResids, FUN = kmeans, nstart = 10, K.max = 10, B = 10)
plot(noWeightGap, main = "K-Means Gap Stat - no weight")

pcNw = prcomp(noWeightResids)
ggNw = as.data.frame(pcNw$x)
ggNw$Weight = nmDat$Weight
ggScatterNw = ggplot(ggNw, aes(x = PC1, y = PC2, color = Weight)) + geom_point() + ggtitle("No weight")
print(ggScatterNw)

plot(ggNw$PC1,ggNw$Weight, xlab = "PC1", ylab = "Weight", main = "No weight")
plot(ggNw$PC2,ggNw$Weight, xlab = "PC2", ylab = "Weight", main = "No weight")

```

Assess residuals from the model without income.There appears to be very few unique values for income; this likely warrants further investigation.

```{r, echo = FALSE}
###gap statistic: not normalized
noIncomeGapNorm = clusGap(noIncomeResids, FUN = kmeans, nstart = 10, K.max = 10, B = 10)
plot(noIncomeGapNorm, main = "K-Means Gap Stat - no income")

pcNiNorm = prcomp(scale(noWeightResids))
ggNiNorm = as.data.frame(pcNiNorm$x)
ggNiNorm$Income = nmDat$Income
ggScatterNiNorm = ggplot(ggNiNorm, aes(x = PC1, y = PC2, color = Income)) + geom_point() + ggtitle("No income")
print(ggScatterNiNorm)

plot(ggNiNorm$PC1,ggNiNorm$Income, xlab = "PC1", ylab = "Income", main = "No income")
legend(legend = paste0("cor: ",round(cor(ggNiNorm$PC1,ggNiNorm$Income), 2)), "topright")
plot(ggNiNorm$PC2,ggNiNorm$Income, xlab = "PC2", ylab = "Income", main = "No income")
legend(legend = paste0("cor: ",round(cor(ggNiNorm$PC2,ggNiNorm$Income), 2)), "topright")

boxplot(ggNiNorm$PC1~as.factor(ggNiNorm$Income), xlab = "Income", ylab = "PC1", main = "No income")
boxplot(ggNiNorm$PC2~as.factor(ggNiNorm$Income), xlab = "Income", ylab = "PC2", main = "No income")
```

Assess residuals from the model without age.

```{r, echo = FALSE}
##gap statistic: not normalized
noAgeGapNorm = clusGap(noAgeResids, FUN = kmeans, nstart = 10, K.max = 10, B = 10)
plot(noAgeGapNorm, main = "K-Means Gap Stat - no age")

pcNageNorm = prcomp(scale(noAgeResids))
ggNageNorm = as.data.frame(pcNageNorm$x)
ggNageNorm$Age = nmDat$Age_x
ggScatterNageNorm = ggplot(ggNageNorm, aes(x = PC1, y = PC2, color = Age)) + geom_point() + ggtitle("No age")
print(ggScatterNageNorm)

plot(ggNageNorm$PC1,ggNageNorm$Age, xlab = "PC1", ylab = "Age", main = "No age")
legend(legend = paste0("cor: ",round(cor(ggNageNorm$PC1,ggNageNorm$Age), 2)), "topright")
plot(ggNageNorm$PC2,ggNageNorm$Age, xlab = "PC2", ylab = "Age", main = "No age")
legend(legend = paste0("cor: ",round(cor(ggNageNorm$PC2,ggNageNorm$Age), 2)), "topright")
```

Assess residuals from the model without education. Compare 4-center k-means clustering to the four education categories with the adjusted Rand index.

```{r, echo = FALSE}
##gap statistic: not normalized
noEdGapNorm = clusGap(noEdResids, FUN = kmeans, nstart = 10, K.max = 10, B = 10)
plot(noEdGapNorm, main = "K-Means Gap Stat - no education")

pcNeNorm = prcomp(scale(noEdResids))
ggNeNorm = as.data.frame(pcNeNorm$x)
ggNeNorm$Education = nmDat$ED_Cat
ggScatterNeNorm = ggplot(ggNeNorm, aes(x = PC1, y = PC2, color = Education)) + geom_point() + ggtitle("No education")
print(ggScatterNeNorm)

fourCenterNeNorm = kmeans(noEdResids, centers = 4, nstart = 3)
print(paste0("Adjusted rand index, no education: ", round(adjustedRandIndex(fourCenterNeNorm$cluster, nmDat$ED_Cat), 3)))
print("No education table of clustering results")
print(table(fourCenterNeNorm$cluster, nmDat$ED_Cat))

boxplot(ggNeNorm$PC1~as.factor(ggNeNorm$Education), xlab = NULL, ylab = "PC1", main = "No education", las = 2)
boxplot(ggNeNorm$PC2~as.factor(ggNeNorm$Education), xlab = NULL, ylab = "PC2", main = "No education", las = 2)
```